{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = r'../data/yahoo_top_products_click_popularity_20200201.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(input_file, sep=r'\\t')\n",
    "\n",
    "# temp descriptions\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parent L1 Description</th>\n",
       "      <th>Parent L2 Description</th>\n",
       "      <th>MID</th>\n",
       "      <th>Merchant Name</th>\n",
       "      <th>OID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Price</th>\n",
       "      <th>Min Offer Price 30 Day</th>\n",
       "      <th>Price Change</th>\n",
       "      <th>Click Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>More Pet Supplies</td>\n",
       "      <td>248942</td>\n",
       "      <td>Chewy.com</td>\n",
       "      <td>9151715234</td>\n",
       "      <td>Wisdom Panel Health Breed &amp; Health Identificat...</td>\n",
       "      <td>Wisdom Panel Health Breed &amp; Health Identificat...</td>\n",
       "      <td>Wisdom Panel</td>\n",
       "      <td>149.99</td>\n",
       "      <td>89.99</td>\n",
       "      <td>66.67</td>\n",
       "      <td>35415.0480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>Men's Clothing</td>\n",
       "      <td>313027</td>\n",
       "      <td>eBay PLA US</td>\n",
       "      <td>11114337071</td>\n",
       "      <td>Girl Scout Cookies 2019-20 New Cookies are in!...</td>\n",
       "      <td>Girl Scout Cookies 2019-20 New Cookies are in!...</td>\n",
       "      <td>Girl Scouts</td>\n",
       "      <td>48.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12215.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>Men's Clothing</td>\n",
       "      <td>134716</td>\n",
       "      <td>MensUSA.com</td>\n",
       "      <td>5651235052</td>\n",
       "      <td>Classic Long Royal Blue Fashion Zoot Suit</td>\n",
       "      <td>\"This Zoot Suit is as nice and unique as it ge...</td>\n",
       "      <td>mensusa</td>\n",
       "      <td>139.00</td>\n",
       "      <td>139.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8317.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>'N/A'</td>\n",
       "      <td>'N/A'</td>\n",
       "      <td>76071</td>\n",
       "      <td>Joe's New Balance Outlet</td>\n",
       "      <td>9756405838</td>\n",
       "      <td>New Balance Women's FuelCore NERGIZE Shoes Bla...</td>\n",
       "      <td>Slip on the FuelCore NERGIZE women's training ...</td>\n",
       "      <td>New Balance</td>\n",
       "      <td>38.99</td>\n",
       "      <td>38.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6132.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>Handbags &amp; Luggage</td>\n",
       "      <td>31851</td>\n",
       "      <td>Kohl's</td>\n",
       "      <td>5681651813</td>\n",
       "      <td>Stone &amp; Co. Irene Leather Hobo, Grey</td>\n",
       "      <td>Watch the product video here. Stone &amp; Co. embo...</td>\n",
       "      <td>Stone &amp; Co.</td>\n",
       "      <td>99.00</td>\n",
       "      <td>69.30</td>\n",
       "      <td>42.85</td>\n",
       "      <td>5251.5413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Parent L1 Description Parent L2 Description     MID  \\\n",
       "0            Pet Supplies     More Pet Supplies  248942   \n",
       "1  Clothing & Accessories        Men's Clothing  313027   \n",
       "2  Clothing & Accessories        Men's Clothing  134716   \n",
       "3                   'N/A'                 'N/A'   76071   \n",
       "4  Clothing & Accessories    Handbags & Luggage   31851   \n",
       "\n",
       "              Merchant Name          OID  \\\n",
       "0                 Chewy.com   9151715234   \n",
       "1               eBay PLA US  11114337071   \n",
       "2               MensUSA.com   5651235052   \n",
       "3  Joe's New Balance Outlet   9756405838   \n",
       "4                    Kohl's   5681651813   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Wisdom Panel Health Breed & Health Identificat...   \n",
       "1  Girl Scout Cookies 2019-20 New Cookies are in!...   \n",
       "2          Classic Long Royal Blue Fashion Zoot Suit   \n",
       "3  New Balance Women's FuelCore NERGIZE Shoes Bla...   \n",
       "4               Stone & Co. Irene Leather Hobo, Grey   \n",
       "\n",
       "                                         Description  Manufacturer   Price  \\\n",
       "0  Wisdom Panel Health Breed & Health Identificat...  Wisdom Panel  149.99   \n",
       "1  Girl Scout Cookies 2019-20 New Cookies are in!...   Girl Scouts   48.00   \n",
       "2  \"This Zoot Suit is as nice and unique as it ge...       mensusa  139.00   \n",
       "3  Slip on the FuelCore NERGIZE women's training ...   New Balance   38.99   \n",
       "4  Watch the product video here. Stone & Co. embo...   Stone & Co.   99.00   \n",
       "\n",
       "   Min Offer Price 30 Day  Price Change  Click Popularity  \n",
       "0                   89.99         66.67        35415.0480  \n",
       "1                   48.00          0.00        12215.2644  \n",
       "2                  139.00          0.00         8317.7750  \n",
       "3                   38.99          0.00         6132.8540  \n",
       "4                   69.30         42.85         5251.5413  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Click Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Buy Art For Less Coastal Nautical Sea Life Sea...</td>\n",
       "      <td>48.99</td>\n",
       "      <td>0.1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Safavieh Light Blue/Dark Blue Adirondack 10 ft...</td>\n",
       "      <td>68.50</td>\n",
       "      <td>0.5798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Funny Prank Blurry Eye Chart Exam T Shirt</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0.1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Opinion Ciatti Gaga 35.43\" H x 45.28\" W Desk H...</td>\n",
       "      <td>1369.99</td>\n",
       "      <td>0.7730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>J. Crew Wool Cardigan Sweater: Black Solid Swe...</td>\n",
       "      <td>21.99</td>\n",
       "      <td>0.3865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title    Price  \\\n",
       "0  Buy Art For Less Coastal Nautical Sea Life Sea...    48.99   \n",
       "1  Safavieh Light Blue/Dark Blue Adirondack 10 ft...    68.50   \n",
       "2          Funny Prank Blurry Eye Chart Exam T Shirt    16.99   \n",
       "3  Opinion Ciatti Gaga 35.43\" H x 45.28\" W Desk H...  1369.99   \n",
       "4  J. Crew Wool Cardigan Sweater: Black Solid Swe...    21.99   \n",
       "\n",
       "   Click Popularity  \n",
       "0            0.1932  \n",
       "1            0.5798  \n",
       "2            0.1932  \n",
       "3            0.7730  \n",
       "4            0.3865  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null Preprocessing\n",
    "null_rows = (df_train['Title'].isnull()) \\\n",
    "            | (df_train['Parent L1 Description'].isnull()) \\\n",
    "            | (df_train['Parent L2 Description'].isnull()) \\\n",
    "            | (df_train['Price'].isnull()) \\\n",
    "            | (df_train['Click Popularity'].isnull())\n",
    "df_train = df_train[~null_rows]\n",
    "\n",
    "# MAX LENGTH substitution\n",
    "#np.max(df_train['Title'].apply(lambda x : len(x)).to_list())\n",
    "MAX_LENGTH = 256\n",
    "df_train = df_train[~(df_train.Title.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
    "\n",
    "# Sampling\n",
    "SAMPLE_FRAC = 0.1\n",
    "df_train = df_train.sample(frac=SAMPLE_FRAC, random_state=9487)\n",
    "\n",
    "# Column Selections\n",
    "df_train = df_train.reset_index()\n",
    "df_train = df_train.loc[:, ['Title', 'Price', 'Click Popularity']]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample number： 170023\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Click Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Buy Art For Less Coastal Nautical Sea Life Sea...</td>\n",
       "      <td>48.99</td>\n",
       "      <td>0.1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Safavieh Light Blue/Dark Blue Adirondack 10 ft...</td>\n",
       "      <td>68.50</td>\n",
       "      <td>0.5798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Funny Prank Blurry Eye Chart Exam T Shirt</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0.1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Opinion Ciatti Gaga 35.43\" H x 45.28\" W Desk H...</td>\n",
       "      <td>1369.99</td>\n",
       "      <td>0.7730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>J. Crew Wool Cardigan Sweater: Black Solid Swe...</td>\n",
       "      <td>21.99</td>\n",
       "      <td>0.3865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title    Price  \\\n",
       "0  Buy Art For Less Coastal Nautical Sea Life Sea...    48.99   \n",
       "1  Safavieh Light Blue/Dark Blue Adirondack 10 ft...    68.50   \n",
       "2          Funny Prank Blurry Eye Chart Exam T Shirt    16.99   \n",
       "3  Opinion Ciatti Gaga 35.43\" H x 45.28\" W Desk H...  1369.99   \n",
       "4  J. Crew Wool Cardigan Sweater: Black Solid Swe...    21.99   \n",
       "\n",
       "   Click Popularity  \n",
       "0            0.1932  \n",
       "1            0.5798  \n",
       "2            0.1932  \n",
       "3            0.7730  \n",
       "4            0.3865  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idempotence\n",
    "df_train.to_csv(\"../data/train.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"sample number：\", len(df_train))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Dataset Generation\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT-format + Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetTextDataset(Dataset):\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"train\", \"test\"]\n",
    "        self.mode = mode\n",
    "        self.df = pd.read_csv(\"../data/\" + mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            text, price = self.df.iloc[idx, :2].values\n",
    "            reg_score_tensor = None\n",
    "        else:\n",
    "            text, price, reg_score = self.df.iloc[idx, :].values\n",
    "            reg_score_tensor = torch.tensor(reg_score)\n",
    "            \n",
    "        # BERT tokens + [SEP]\n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        word_pieces += tokens + [\"[SEP]\"]\n",
    "        len_text = len(word_pieces)\n",
    "        \n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        \n",
    "        segments_tensor = torch.tensor([0] * len_text, dtype=torch.long)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, reg_score_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TargetTextDataset(\"train\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_diff_dataset(dataset, index=0):\n",
    "    # 選擇第一個樣本\n",
    "    sample_idx = index\n",
    "\n",
    "    # 將原始文本拿出做比較\n",
    "    text_a, price_a, reg_score_a = trainset.df.iloc[sample_idx].values\n",
    "\n",
    "    # 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n",
    "    tokens_tensor, segments_tensor, reg_score_tensor = trainset[sample_idx]\n",
    "\n",
    "    # 將 tokens_tensor 還原成文本\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "    combined_text = \" \".join(tokens)\n",
    "\n",
    "    # 渲染前後差異，毫無反應就是個 print。可以直接看輸出結果\n",
    "    print(f\"\"\"[原始文本]\n",
    "    句子 1：{text_a}\n",
    "    句子 2：{price_a}\n",
    "    分類  ：{reg_score_a}\n",
    "\n",
    "    --------------------\n",
    "\n",
    "    [Dataset 回傳的 tensors]\n",
    "    tokens_tensor  ：{tokens_tensor}\n",
    "\n",
    "    segments_tensor：{segments_tensor}\n",
    "\n",
    "    label_tensor   ：{reg_score_tensor}\n",
    "\n",
    "    --------------------\n",
    "\n",
    "    [還原 tokens_tensors]\n",
    "    {combined_text}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[原始文本]\n",
      "    句子 1：Buy Art For Less Coastal Nautical Sea Life Sea Shell Typography 'Pamper Yourself Dream' by Jean Plout Framed Graphic Art Print IF JP1777 16x16 White 1.5 SM\n",
      "    句子 2：48.99\n",
      "    分類  ：0.1932\n",
      "\n",
      "    --------------------\n",
      "\n",
      "    [Dataset 回傳的 tensors]\n",
      "    tokens_tensor  ：tensor([  101,  4965,  2396,  2005,  2625,  5780, 11339,  2712,  2166,  2712,\n",
      "         5806,  5939,  6873, 12565,  1005, 14089,  4842,  4426,  3959,  1005,\n",
      "         2011,  3744, 20228,  5833, 10366,  8425,  2396,  6140,  2065, 16545,\n",
      "        16576,  2581,  2581,  2385,  2595, 16048,  2317,  1015,  1012,  1019,\n",
      "        15488,   102])\n",
      "\n",
      "    segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "    label_tensor   ：0.1932000070810318\n",
      "\n",
      "    --------------------\n",
      "\n",
      "    [還原 tokens_tensors]\n",
      "    [CLS] buy art for less coastal nautical sea life sea shell ty ##po ##graphy ' pam ##per yourself dream ' by jean pl ##out framed graphic art print if jp ##17 ##7 ##7 16 ##x ##16 white 1 . 5 sm [SEP]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "check_diff_dataset(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    # 測試集有 labels\n",
    "    if samples[0][2] is not None:\n",
    "        reg_score = torch.stack([s[2] for s in samples])\n",
    "    else:\n",
    "        reg_score = None\n",
    "    \n",
    "    # zero pad 到同一序列長度\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
    "                                dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(\n",
    "        tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, reg_score\n",
    "\n",
    "\n",
    "# 初始化一個每次回傳 64 個訓練樣本的 DataLoader\n",
    "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n",
    "BATCH_SIZE = 64\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataloader(dataloader):\n",
    "    data = next(iter(dataloader))\n",
    "\n",
    "    tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, reg_score = data\n",
    "\n",
    "    print(f\"\"\"\n",
    "    tokens_tensors.shape   = {tokens_tensors.shape} \n",
    "    {tokens_tensors}\n",
    "    ------------------------\n",
    "    segments_tensors.shape = {segments_tensors.shape}\n",
    "    {segments_tensors}\n",
    "    ------------------------\n",
    "    masks_tensors.shape    = {masks_tensors.shape}\n",
    "    {masks_tensors}\n",
    "    ------------------------\n",
    "    label_ids.shape        = {reg_score.shape}\n",
    "    {reg_score}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    tokens_tensors.shape   = torch.Size([64, 46]) \n",
      "    tensor([[  101,  4965,  2396,  ...,     0,     0,     0],\n",
      "        [  101,  7842,  7011,  ...,     0,     0,     0],\n",
      "        [  101,  6057, 26418,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 27327, 11721,  ...,     0,     0,     0],\n",
      "        [  101,  2033,  5004,  ...,     0,     0,     0],\n",
      "        [  101, 28576, 23858,  ...,     0,     0,     0]])\n",
      "    ------------------------\n",
      "    segments_tensors.shape = torch.Size([64, 46])\n",
      "    tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "    ------------------------\n",
      "    masks_tensors.shape    = torch.Size([64, 46])\n",
      "    tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "    ------------------------\n",
      "    label_ids.shape        = torch.Size([64])\n",
      "    tensor([ 0.1932,  0.5798,  0.1932,  0.7730,  0.3865,  0.3865,  0.1932,  0.1932,\n",
      "         0.1932, 82.7197,  0.1932,  0.3865,  0.1932,  0.7730,  0.3865,  0.1932,\n",
      "         1.3528,  0.1932,  0.3865,  0.1932,  0.3865,  0.5798,  0.1932,  0.5798,\n",
      "         0.3865,  0.1932,  0.1932,  0.1932,  0.3865,  0.1932,  0.7730,  0.1932,\n",
      "         0.3865,  0.1932,  8.5038,  0.1932,  0.1932,  0.3865,  0.3865,  0.1932,\n",
      "         7.7308,  0.5798,  0.1932,  0.5798,  3.4788,  0.3865,  0.1932,  0.1932,\n",
      "         0.1932,  0.1932,  0.3865,  0.1932,  0.1932,  1.3528,  0.7730,  0.1932,\n",
      "         0.1932,  0.1932,  0.1932,  0.1932,  0.1932,  0.1932,  0.9663,  0.5798])\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "check_dataloader(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "- Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name            module\n",
      "----------------------\n",
      "bert:embeddings\n",
      "bert:encoder\n",
      "bert:pooler\n",
      "dropout         Dropout(p=0.1, inplace=False)\n",
      "classifier      Linear(in_features=768, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# 載入一個可以做中文多分類任務的模型，n_class = 3\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "#PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "NUM_LABELS = 1\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
    "\n",
    "#clear_output()\n",
    "\n",
    "# high-level 顯示此模型裡的 modules\n",
    "print(\"\"\"\n",
    "name            module\n",
    "----------------------\"\"\")\n",
    "for name, module in model.named_children():\n",
    "    if name == \"bert\":\n",
    "        for n, _ in module.named_children():\n",
    "            print(f\"{name}:{n}\")\n",
    "    else:\n",
    "        print(\"{:15} {}\".format(name, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"do_sample\": false,\n",
       "  \"eos_token_ids\": 0,\n",
       "  \"finetuning_task\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"is_decoder\": false,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"length_penalty\": 1.0,\n",
       "  \"max_length\": 20,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_beams\": 1,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"num_labels\": 1,\n",
       "  \"num_return_sequences\": 1,\n",
       "  \"output_attentions\": false,\n",
       "  \"output_hidden_states\": false,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pruned_heads\": {},\n",
       "  \"repetition_penalty\": 1.0,\n",
       "  \"temperature\": 1.0,\n",
       "  \"top_k\": 50,\n",
       "  \"top_p\": 1.0,\n",
       "  \"torchscript\": false,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_bfloat16\": false,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            \n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                labels = data[3]\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc\n",
    "    return predictions\n",
    "    \n",
    "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "_, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "print(\"classification acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    @add_start_docstrings_to_callable(BERT_INPUTS_DOCSTRING)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
    "            Labels for computing the sequence classification/regression loss.\n",
    "            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n",
    "            If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "    Returns:\n",
    "        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.BertConfig`) and inputs:\n",
    "        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n",
    "            Classification (or regression if config.num_labels==1) loss.\n",
    "        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n",
    "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n",
    "            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "    Examples::\n",
    "        from transformers import BertTokenizer, BertForSequenceClassification\n",
    "        import torch\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss, logits = outputs[:2]\n",
    "        \"\"\"\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
